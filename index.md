# Utku Türk
## Application Materials for University of Chicago

**PhD Candidate in Linguistics**
University of Maryland, College Park
[utkuturk@umd.edu](mailto:utkuturk@umd.edu) | [utkuturk.com](https://utkuturk.com) | [GitHub](https://github.com/utkuturk)

---

## Application Documents

### Core Materials
- **[Cover Letter](cover_letter.md)** - Letter of application for the Instructional Faculty position
- **[Teaching Statement](teaching_statement.md)** - My approach to teaching linguistics through operationalization and hands-on learning
- **[Curriculum Vitae (PDF)](cv_utkuturk.pdf)** - Complete academic CV

---

## Sample Course Syllabi

I've developed seven distinctive course syllabi demonstrating my teaching breadth across psycholinguistics, computational methods, and AI/NLP:

### Psycholinguistics & Language Processing

#### [Introduction to Psycholinguistics](syllabi/intro_psycholing.md)
**Learning Through the Experimental Process**
*Undergraduate/Graduate | Fall 2026*

An apprenticeship in experimental psycholinguistics. Students work through the complete research cycle multiple times, building mini-experiments from question formation to data analysis. Features a unique **Experiment Building Timeline** showing weekly milestones.

**Key Features:** QALMRI framework, hands-on labs, HSP conference project, full experimental workflow

---

#### [Linguistic Illusions: From Illusions to Inference](syllabi/linguistic_illusions.md)
**Graduate Seminar | Fall 2026*

A debate-focused seminar on linguistic illusions built around **intellectual combat**. Students defend assigned theoretical positions (even those they don't believe!) and interrogate competing mechanisms: shallow processing, cue-based retrieval, and noisy channel.

**Key Features:** Debate format, weekly synthesis papers, "Illusion of the Week" with provocative questions

---

#### [Morphology in Production: How Words Are Built](syllabi/morphology_production.md)
**Graduate Seminar | Fall 2026**

A **studio-model** seminar where half our time is spent building: writing code, designing experiments, debugging analyses. Includes peer workshop sessions and collaborative build-athons.

**Key Features:** PCIbex implementation, R analysis, preregistration, article-format final projects

---

### Quantitative Methods

#### [Quantitative Methods for Linguistics](syllabi/quant_methods.md)
**R, Bayesian Statistics, and Reproducible Research**
*Undergraduate/Graduate | Fall 2026*

A **simulation-first** approach to statistics. Students learn to think like statisticians by building models from the ground up through simulation. Features weekly **Simulation Challenges** (coding puzzles).

**Key Features:** R/Stan, Bayesian inference, mixed-effects models, power analysis, Quarto reproducibility

---

#### [Bayesian Cognitive Modeling for Linguistics](syllabi/bayesian_modeling.md)
**From Theory to Implementation**
*Advanced Graduate | Fall 2026*

Teaches students to think like **theoreticians**: "If my theory is true, what data would I see?" Features weekly **Mathematical Intuition Building** before touching code. Six-step workflow from theory to implementation.

**Key Features:** Generative stance, Stan implementation, parameter recovery, model comparison

---

### AI and Natural Language Processing

#### [Machine Learning for Language](syllabi/intro_ai_language.md)
**Neural Networks, Linguistic Structure, and NLP Applications**
*Undergraduate/Graduate | Fall 2026*

Beginner-friendly course balancing technical foundations with linguistic questions. Features **The Three Questions** framework (What can it do? What can't it do? What does that tell us?) and **Model of the Week** spotlight.

**Key Features:** Build neural nets from scratch, implement backprop by hand, PyTorch, probing experiments

---

#### [Advanced NLP & AI for Linguistics](syllabi/advanced_nlp_ai.md)
**Attention Probing, Causality, and Interpretability**
*Advanced Graduate | Spring 2027*

Research-level seminar on cutting-edge interpretability methods. Features **Paper Presentation Rotation** with 4-step structure and **Method Implementation Showcase** where students demonstrate discoveries.

**Key Features:** Probing classifiers, causal intervention, attention analysis, counterfactual methods

---

## Teaching Philosophy

My teaching is built on three principles:

1. **Operationalization**: Claims are only as good as their operationalization. Students learn to turn informal claims into explicit hypotheses that can be tested.

2. **Full Pipeline Integration**: Theory motivates design, design determines evidence, analysis makes assumptions visible. Not separate silos, but one integrated process.

3. **Hands-on Learning**: Students predict patterns before seeing data, work through complete workflows, and leave with authentic products—reproducible analyses, replication reports, pilot studies, and computational models.

Each syllabus reflects a distinct pedagogical approach:
- **Intro Psycholing**: Apprenticeship model
- **Quant Methods**: Simulation-first lab
- **Intro AI**: Three Questions framework
- **Advanced NLP**: Research seminar
- **Linguistic Illusions**: Intellectual combat arena
- **Morphology Production**: Studio/maker space
- **Bayesian Modeling**: Theoretician's approach

---

## Research Highlights

My research investigates how **morphosyntactic structure** and **morphophonological form** are planned in production and retrieved during comprehension:

- **Production**: Investigating the flexibility and timing of morphological planning using experimental methods
- **Comprehension**: Understanding agreement attraction and memory retrieval failures in Turkish and cross-linguistically
- **Language Documentation**: Creating Universal Dependencies treebanks for underrepresented languages (Laz, Ladino, Cappadocian Greek)
- **Computational Methods**: Advanced Bayesian modeling, experimental psycholinguistics, corpus annotation

### Selected Publications
- Türk, U., Logačev, P. (2024). "Agreement Attraction in Turkish: The case of genitive attractors." *Language, Cognition, and Neuroscience*.
- Türk, U., Atmaca, F., Özateş, Ş.B. et al. (2022). "Resources for Turkish dependency parsing: introducing the BOUN Treebank and the BoAT annotation tool." *Language Resources & Evaluation*, 56, 259–307.

---

## Technical Expertise

**Expert-level:**
- R programming (brms, ggplot2, dplyr, cmdstanr, lme4)
- Bayesian hierarchical modeling
- Git/GitHub with CI/CD

**Advanced:**
- Python (PyMC3, pandas, transformers)
- LaTeX, Quarto, Rmarkdown
- Web-based experiments (PCIbex, jsPsych)
- Linux/bash, Docker, AWS

---

## Contact

**Email:** utkuturk@umd.edu
**Website:** [utkuturk.com](https://utkuturk.com)
**GitHub:** [github.com/utkuturk](https://github.com/utkuturk)
**Google Scholar:** [Profile](https://scholar.google.com/citations?hl=tr&user=wa7LG9gAAAAJ)

---

*Last updated: January 2026*
