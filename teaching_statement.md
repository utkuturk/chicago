I teach linguistics as a discipline where claims are only as good as
their operationalization. In my courses, students learn to turn an
informal claim about structure or meaning into an explicit hypothesis
about cognition that can be implemented as an experiment, a principled
measurement choice, and a statistical model, yielding predictions a
reader can actually evaluate. I treat the research pipeline as a single
integrated object rather than a sequence of separate parts: theory
motivates design, design determines what counts as evidence, and
analysis makes assumptions visible. To build this intuition hands-on,
students predict patterns before seeing data, work through the full
workflow (hypothesis → design → data → model → interpretation →
limitations), and leave with authentic products ranging from reproducible
analyses and replication reports to research proposals and—where
feasible within a semester—pilot studies, computational models,
and cross-linguistic extensions that encode explicit hypotheses about
human linguistic cognition and, when appropriate, its relationship to
machine behavior.

**\
Teaching Experience and Instructional Roles.** My teaching experience
spans large-lecture support, methods-intensive instruction, and
workshop-based mentoring. At the University of Maryland, I have TA'd
core offerings including Language and Mind and Grammars and Cognition
(LING 440), and I served as experimental instructor in the graduate
Psycholinguistics seminar (LING 640), where I taught a module on
experimental methods and statistical analysis. I have also supported
interdisciplinary teaching (including a course on Machine Learning in
Language and Art), which has sharpened my ability to make technical
material accessible to students with diverse preparation.

In my teaching for LING 440 and LING 640, I have repeatedly taken
students through the full research pipeline. Students read a focused set
of papers in depth (e.g., illusion phenomena in comprehension in 440;
prosody and center-embedding in 640), extract core assumptions and
predictions, and design a decisive follow-up test. We collaboratively
build materials, choose a measurement and methodology, implement the
experiment, and interpret the resulting patterns, often going far enough
to fit and critique an appropriate statistical model. My goal is that
students leave not only able to summarize a literature, but able to turn
an idea into an experiment and an analysis.

I have also taught in an intensive workshop setting. At the University
of Oxford, I co-organized and helped instruct a workshop on sentence
production in which participants developed production experiments from
the ground up. Students read relevant literature, articulated a precise
theoretical question, designed materials (including critical contrasts
and fillers), selected an elicitation and measurement strategy, and
implemented a runnable experiment. A major focus of my role was
technical and methodological mentoring, helping participants translate
an idea into an executable study and a defensible analysis plan.

Before Maryland, at Boğaziçi University I served as a teaching assistant
across the linguistics curriculum, ranging from core theoretical courses
(Syntax, Morphology, Typology) to methodological and language-specific
offerings (Computational Methods, Turkish Morphosyntax). In
methods-focused instruction, I led problem sessions and developed
course-support materials aimed at building students' competence with
real data (cleaning, visualization, and basic modeling). Workshop
teaching has sharpened my ability to help students move from an idea to
a workable pipeline quickly, concretely, and without lowering standards.

**Courses I Am Prepared to Teach**

*Psycholinguistics and Language Processing.* In psycholinguistics, I aim
to demystify how research turns theoretical questions into decisive
tests. Students often understand a study's results while missing the
chain of decisions that make the results informative. To address this, I
structure units around the lifecycle of an experiment: identifying a
theoretical question, isolating confounds, designing materials,
collecting data, modeling, and interpreting limitations. Long-standing
debates in the field serve as case studies for each stage of this
lifecycle.

A central pedagogical tool is replication-and-extension. Rather than
presenting agreement attraction as a single effect, I give students data
showing divergent patterns across languages or tasks and ask them to
work backward: which variables are confounded, what minimal follow-up
experiment would adjudicate between competing accounts, and what result
would actually force an update? This is where I integrate practical
training---experiment building and data analysis---as steps required by
the theoretical question, not as add-ons. Teaching these skills hands-on
is essential for an introductory psycholinguistics course: living
through the workflow demystifies the decisions.

*Quantitative Research Methods.* My goal in methods courses is to make
statistics a way of thinking rather than a set of scripts: what does the
model assume about how data is generated, and what would count as
evidence against it? Because many students approach statistics with
anxiety, I begin with intuition---what question a method answers and why
it works---before implementation. I build this intuition from basics:
statistics is structured counting paired with an informed guess on
causation. Once the logic is clear, we work with real, messy data and
treat modeling as a workflow: specification, diagnostics, and
interpretation, not merely significance testing.

A typical arc emphasizes downstream consequences of design choices and
moves from design and measurement to linear and generalized linear
models, mixed-effects thinking, and Bayesian approaches that make
uncertainty and prior commitments explicit. The causal question is
present from the beginning and is guided by theory and typology.
Students practice the full pipeline from theoretical hypothesis to
implementable study to reproducible analysis, rather than encountering
methods and modeling as separate silos that can be skipped in assigned
papers.

*Cognitive Models and Computational Modeling.* In computational
modeling, I treat models as commitments: explicit hypotheses whose
assumptions should be inspected and tested. Students learn to separate
(i) descriptive fit, (ii) generalization, and (iii) interpretation. I
structure these courses around a foundations-to-frontiers progression:
first giving students the programming and mathematical footing needed to
implement models, then moving to research questions where modeling
choices have theoretical consequences.

Concretely, the course combines close reading of classic and current
work with regular programming exercises in Python/R/Stan. The goal is
methodological independence: students should be able to take a
theoretical claim and ask what computations it entails. A central
capstone is a final project in which students either implement a simple
model to address a question about language processing or evaluate an
existing model using cross-linguistic data.

*Artificial Intelligence and Contemporary Topics.* For AI-adjacent
courses aimed at linguistics and cognitive science students, I emphasize
critical interpretation: these systems often achieve predictive success
for reasons that do not align with human mechanisms. At the same time,
their internal structure can be a useful instrument for formalizing
assumptions that are otherwise hard to state precisely and for testing
hypotheses at scale. For example, students can quantify whether a system
treats a morphological cue as evidence for controllerhood, a
theoretically grounded heuristic in human processing.

I also introduce counterfactual intervention as a way to make evaluation
more diagnostic: hold context constant, manipulate one targeted
linguistic property, and test whether the model's behavior changes in
the way a hypothesis predicts. In practice, this means teaching students
to design evaluations that target specific linguistic generalizations
and to use transparent analyses to connect model behavior to claims
about representation, learning, and inference. Students begin applying
these counterfactual methods in introductory courses and develop
sophisticated intervention designs in advanced seminars.

**Mentorship and Advising.** Mentorship is an extension of teaching: a
more involved setting where students learn to scope questions, build
workflows, and communicate results. For thesis advising, I encourage
projects that are methodologically realistic yet intellectually
substantive---replications/extensions, corpus-and-experiment
combinations, or carefully constrained modeling projects---so students
learn how to make strong claims from limited time and data. Science
advances when we commit to clear predictions while staying willing to be
wrong.

I would relish the opportunity to co-teach or co-advise with faculty
whose expertise is complementary to mine. Ming Xiang and Melissa
Baese-Berk would be ideal partners for courses in psycholinguistics and
language processing that connect real-time comprehension to experimental
method; Karlos Arregi provides a natural connection to formal approaches
to morphosyntax that I would integrate into production research; and
Craig Thorburn is an ideal colleague for co-developing lasting
curriculum in computational linguistics and quantitative methods that
will outlast temporary hypes.

My aim as an instructional faculty member is to produce students who can
(i) reason from theory to prediction, (ii) evaluate evidence with
methodological clarity, and (iii) communicate conclusions with precision
and humility. My teaching is designed to give students repeated
opportunities to practice the work of the field, so they leave not only
knowledgeable, but genuinely capable.
